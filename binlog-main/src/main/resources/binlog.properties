#hdfs
#hdfs.temp.url hdfs://dn0:8020/data/temp
#hdfs.temp.url hdfs://cloudera2:8020/data/temp
hdfs.temp.url hdfs://localhost:9000/data/temp
#hdfs.warehouse.url hdfs://dn0:8020/data/warehouse
#hdfs.warehouse.url hdfs://cloudera2:8020/data/warehouse
hdfs.warehouse.url hdfs://localhost:9000/data/warehouse
#jdbc properties
jdbc.driverClassName=com.mysql.jdbc.Driver
jdbc.url=jdbc:mysql://master0:3306/my_test?characterEncoding=utf8
#jdbc.url=jdbc:mysql://cloudera1:3306/binlog?characterEncoding=utf8
#jdbc.username=cloudera1
jdbc.username=root
#jdbc.password=cloudera0701!
jdbc.password=123456
binlog.record.table=t_binlog_record
#task
queue.dispense.class=com.datatrees.datacenter.core.task.RabbitMqDispensor
queue.process.class=com.datatrees.datacenter.resolver.RabbitMqProcessor
queue.server=hadoop13
queue.port=5672
queue.topic=taskQueue_local
#queue.topic=taskQueue
max.thread.binlog.thread=10
runner.class=com.datatrees.datacenter.resolver.RabbitMqProcessor
#runner.class=com.datatrees.datacenter.transfer.process.TransferTimerTask
#processCheck 任务超时时间
process.check.interval=120
#processCheck 任务超时时间刻度 hour\minute\second
process.check.time.scale=minute
#processCheck 定时任务启动延时
process.check.schedule.task.initaildelay=0
#processCheck 定时任务定时执行间隔(时间刻度为分钟)
process.check.schedule.task.period=10
#binlog下载多线程线程池相关设置
thread.pool.corePoolSize=5
thread.pool.maximumPoolSize=10
thread.pool.keepAliveTime=2
#binlog下载定时任务时间参数
#AliBinLogFileTransfer 定时任务启动延时
AliBinLogFileTransfer.check.schedule.task.initaildelay=0
#AliBinLogFileTransfer 定时任务定时执行间隔(时间刻度为分钟)
AliBinLogFileTransfer.check.schedule.task.period=2
#schema
port 3306
user debezium
password Debezium_
#aliyun properties
# aliyun 相关配置
REGION_ID=cn-hangzhou
ACCESS_KEY_ID=LTAIAfBoz0Wz5O6L
ACCESS_SECRET=WGlWEscL3u5rfFrokhYle4jFXsXBv9
#截取文件正则
REGEX_PATTERN=(mysql-bin\\.)(.*)(\\.tar)
#hdfs文件路径
#HDFS_PATH=hdfs://dn0:8020/pc
HDFS_PATH=hdfs://cloudera2:8020/pc
#HDFS_PATH=hdfs://dn0:8020/pc
BINLOG_ACTION_NAME=DescribeBinlogFiles
PAGE_SIZE=30
DOWN_TIME_INTERVAL=1500
DBINSTANCE_LIST=rm-bp13sd5q1x8416p3p,rm-bp1h5j9w2o9335zsn
BUFFER_SIZE=1024
#redis
#master.redis.server hadoop11:26379
#slave.redis.server hadoop12:26379
redis.master.name=mymaster
redis.sentinel.address=redis://10.1.2.210:36379,redis://10.1.2.209:36379

#partition
update=LastUpdateDate,lastupdate_date,UpdateDate,last_update_date,last_update_time,LastUpdate,UpdateTime,update_date,updatedAt,LastUpdatedDatetime,LastUpdateTime
create=create_time,CreateDate,create_date,CreateTime,CreatTime,create_date,createtime,createdate,createTime,createdAt,CreatedDatetime