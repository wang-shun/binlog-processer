#hdfs
#hdfs.temp.url hdfs://dn0:8020/data/temp
#hdfs.temp.url hdfs://cloudera2:8020/data/temp
#temp.url /Users/zxding1986/Downloads/data_temp
temp.url /data0/application/binlog-process/tmp
#hdfs.warehouse.url hdfs://dn0:8020/data/warehouse
#hdfs.warehouse.url hdfs://cloudera2:8020/data/warehouse
hdfs.warehouse.url hdfs://nameservice1/data/warehouse
#hdfs.warehouse.url hdfs://localhost:9000/data/warehouse
#hdfs.site /Users/zxding1986/src/ideaworkbench/CDH/exe/hadoop-2.6.0-cdh5.12.1/etc/hadoop/core-site.xml
#jdbc properties
jdbc.driverClassName=com.mysql.jdbc.Driver
#jdbc.url=jdbc:mysql://master0:3306/my_test?characterEncoding=utf8
jdbc.url=jdbc:mysql://cloudera1:3306/binlog?characterEncoding=utf8
jdbc.username=cloudera
#jdbc.username=root
jdbc.password=cloudera0701!
#jdbc.password=123456
binlog.record.table=t_binlog_record
#task
queue.dispense.class=com.datatrees.datacenter.core.task.RabbitMqDispensor
queue.process.class=com.datatrees.datacenter.resolver.RabbitMqProcessor
queue.server=hadoop13
queue.port=5672
#queue.topic=taskQueue_local
queue.topic=taskQueue
max.thread.binlog.thread=10
#写入avro的buffer大小
avro.message.buffer.size=1000
runner.class=com.datatrees.datacenter.resolver.RabbitMqProcessor
#runner.class=com.datatrees.datacenter.transfer.process.TransferTimerTask
#processCheck 任务超时时间
process.check.interval=10
#processCheck 任务超时时间刻度 hour\minute\second
process.check.time.scale=minute
#processCheck 定时任务启动延时
process.check.schedule.task.initaildelay=0
#processCheck 定时任务定时执行间隔(时间刻度为分钟)
process.check.schedule.task.period=10
#retry 次数
process.check.schedule.task.retry=3
#binlog下载多线程线程池相关设置
thread.pool.corePoolSize=5
thread.pool.maximumPoolSize=10
thread.pool.keepAliveTime=2
#binlog下载定时任务时间参数
#AliBinLogFileTransfer 定时任务启动延时
AliBinLogFileTransfer.check.schedule.task.initaildelay=0
#AliBinLogFileTransfer 定时任务定时执行间隔(时间刻度为分钟)
AliBinLogFileTransfer.check.schedule.task.period=30
#schema
port 3306
user debezium
password Debezium_
#aliyun properties
# aliyun 相关配置
REGION_ID=cn-hangzhou
ACCESS_KEY_ID=LTAIAfBoz0Wz5O6L
ACCESS_SECRET=WGlWEscL3u5rfFrokhYle4jFXsXBv9
#截取文件正则
REGEX_PATTERN=(mysql-bin\\.)(.*)(\\.tar)
#hdfs文件路径
#HDFS_PATH=hdfs://dn0:8020/pc
#HDFS_PATH=hdfs://cloudera2:8020/pc
HDFS_PATH=hdfs://nameservice1/pc
#HDFS_PATH=hdfs://localhost:9000/pc
#HDFS_PATH=hdfs://dn0:8020/pc
BINLOG_ACTION_NAME=DescribeBinlogFiles
PAGE_SIZE=30
DOWN_TIME_INTERVAL=5000
#DBINSTANTCE_1
#DBINSTANCE_LIST=rm-bp1tcbap8lvphh08x,rm-bp1v9i4pwb73467g5,rm-bp15112z7tv876mzl,rm-bp101325tnut8me53,rm-bp17mz8twp1c71zk2,rm-bp18uypc15s63z5xa,rm-bp19ok2k1h1dcwk6e,rm-bp14007m55u6a9173,rm-bp114u46sxgr719pf,rm-bp1htjis5cxoufia6,rm-bp1k0lx0x43542h47,rm-bp11fjyus6cugmvd2,rm-bp1x3mt0ogici00l5,rm-bp1bgyn06wua3s262
#DBINSTANTCE_2
#DBINSTANCE_LIST=rm-bp1cowwkt73ni6271,rm-bp1p4s8pgekg2di55,rm-bp1dq0cr4kk7j85ff,rm-bp12z0brmm2d799lm,rm-bp1hzldabba9nhm68,rm-bp19wpb29u91pbf6p,rm-bp159o69998x3xe34,rm-bp155hg16d7t501f6,rm-bp1382ojqe4u01d1t,rm-bp1d1ac1fa41jzf28,rm-bp11gox03jgt2ullb,rm-bp1xvc22l77p850ja,rm-bp14hbsc7ji8ivy7r,rm-bp1py1768bl28z5zs
#DBINSTANCE_LIST=rm-bp1cowwkt73ni6271,rm-bp1p4s8pgekg2di55,rm-bp1dq0cr4kk7j85ff,rm-bp12z0brmm2d799lm,rm-bp1hzldabba9nhm68,rm-bp19wpb29u91pbf6p,rm-bp159o69998x3xe34,rm-bp155hg16d7t501f6,rm-bp1382ojqe4u01d1t,rm-bp1d1ac1fa41jzf28,rm-bp11gox03jgt2ullb,rm-bp1xvc22l77p850ja,rm-bp14hbsc7ji8ivy7r,rm-bp1py1768bl28z5zs,rm-bp1tcbap8lvphh08x,rm-bp1v9i4pwb73467g5,rm-bp15112z7tv876mzl,rm-bp101325tnut8me53,rm-bp17mz8twp1c71zk2,rm-bp18uypc15s63z5xa,rm-bp19ok2k1h1dcwk6e,rm-bp14007m55u6a9173,rm-bp114u46sxgr719pf,rm-bp1htjis5cxoufia6,rm-bp1k0lx0x43542h47,rm-bp11fjyus6cugmvd2,rm-bp1x3mt0ogici00l5,rm-bp1bgyn06wua3s262
BUFFER_SIZE=1024
#redis
redis.master.name=mymaster
redis.sentinel.address=redis://10.1.2.210:36379,redis://10.1.2.209:36379
#partition
update=LastUpdateDate,lastupdate_date,UpdateDate,last_update_date,last_update_time,LastUpdate,UpdateTime,update_date,updatedAt,LastUpdatedDatetime,LastUpdateTime
create=create_time,CreateDate,create_date,CreateTime,CreatTime,create_date,createtime,createdate,createTime,createdAt,CreatedDatetime
#binlog-service
subscribe.topics=dbhistory.*
#binlog-service kafka consumer properties
binlog.service.kafka.bootstrap.servers=kafka1:9092
binlog.service.kafka.group.id=client-history-loader-test-1
binlog.service.kafka.enable.auto.commit=false
binlog.service.kafka.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
binlog.service.kafka.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
binlog.service.kafka.auto.offset.reset=earliest
binlog.service.kafka.max.partition.fetch.bytes=5242880