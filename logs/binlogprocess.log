2018-06-13 14:55:35 [ INFO] - com.mchange.v2.log.MLog -MLog.java(92) -MLog clients using log4j logging.
2018-06-13 15:01:59 [ INFO] - org.redisson.Version -Version.java(41) -Redisson 3.6.0
2018-06-13 15:02:02 [ INFO] - org.redisson.connection.pool.MasterConnectionPool -ConnectionPool.java(144) -10 connections initialized for master0/172.20.24.8:6379
2018-06-13 15:02:02 [ INFO] - org.redisson.connection.pool.MasterPubSubConnectionPool -ConnectionPool.java(144) -1 connections initialized for master0/172.20.24.8:6379
2018-06-13 15:02:50 [ INFO] - org.redisson.Version -Version.java(41) -Redisson 3.6.0
2018-06-13 15:02:50 [ INFO] - org.redisson.connection.pool.MasterConnectionPool -ConnectionPool.java(144) -10 connections initialized for master0/172.20.24.8:6379
2018-06-13 15:02:50 [ INFO] - org.redisson.connection.pool.MasterPubSubConnectionPool -ConnectionPool.java(144) -1 connections initialized for master0/172.20.24.8:6379
2018-06-13 15:03:58 [ INFO] - org.redisson.Version -Version.java(41) -Redisson 3.6.0
2018-06-13 15:03:59 [ INFO] - org.redisson.connection.pool.MasterConnectionPool -ConnectionPool.java(144) -10 connections initialized for master0/172.20.24.8:6379
2018-06-13 15:03:59 [ INFO] - org.redisson.connection.pool.MasterPubSubConnectionPool -ConnectionPool.java(144) -1 connections initialized for master0/172.20.24.8:6379
2018-06-13 15:15:52 [ERROR] - com.datatrees.datacenter.main.Main -Main.java(29) -
java.lang.NullPointerException
	at com.datatrees.datacenter.main.Main.main(Main.java:27)
2018-06-13 15:21:33 [ERROR] - com.datatrees.datacenter.main.Main -Main.java(29) -
java.lang.NullPointerException
	at com.datatrees.datacenter.main.Main.main(Main.java:27)
2018-06-13 15:25:59 [ INFO] - org.redisson.Version -Version.java(41) -Redisson 3.6.0
2018-06-13 15:26:01 [ INFO] - org.redisson.connection.pool.MasterConnectionPool -ConnectionPool.java(144) -10 connections initialized for master0/172.20.24.8:6379
2018-06-13 15:26:01 [ INFO] - org.redisson.connection.pool.MasterPubSubConnectionPool -ConnectionPool.java(144) -1 connections initialized for master0/172.20.24.8:6379
2018-06-13 15:26:18 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1cowwkt73ni6271_1528856961000-mysql-bin.000103.tar","identity0":"rm-bp1cowwkt73ni6271","identity1":"1528856961000-mysql-bin.000103.tar","instanceId":"telemarketing","jdbcUrl":"telemarketing.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1cowwkt73ni6271/4615201/1528856961000-mysql-bin.000103.tar"}
2018-06-13 15:26:18 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1cowwkt73ni6271_1528835357000-mysql-bin.000102.tar","identity0":"rm-bp1cowwkt73ni6271","identity1":"1528835357000-mysql-bin.000102.tar","instanceId":"telemarketing","jdbcUrl":"telemarketing.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1cowwkt73ni6271/4615201/1528835357000-mysql-bin.000102.tar"}
2018-06-13 15:26:18 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1cowwkt73ni6271_1528813755000-mysql-bin.000101.tar","identity0":"rm-bp1cowwkt73ni6271","identity1":"1528813755000-mysql-bin.000101.tar","instanceId":"telemarketing","jdbcUrl":"telemarketing.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1cowwkt73ni6271/4615201/1528813755000-mysql-bin.000101.tar"}
2018-06-13 15:26:18 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1p4s8pgekg2di55_1528871946000-mysql-bin.000179.tar","identity0":"rm-bp1p4s8pgekg2di55","identity1":"1528871946000-mysql-bin.000179.tar","instanceId":"basisdataecommerce","jdbcUrl":"basisdataecommerce2.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1p4s8pgekg2di55/4500933/1528871946000-mysql-bin.000179.tar"}
2018-06-13 15:26:18 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1p4s8pgekg2di55_1528850344000-mysql-bin.000178.tar","identity0":"rm-bp1p4s8pgekg2di55","identity1":"1528850344000-mysql-bin.000178.tar","instanceId":"basisdataecommerce","jdbcUrl":"basisdataecommerce2.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1p4s8pgekg2di55/4500933/1528850344000-mysql-bin.000178.tar"}
2018-06-13 15:26:18 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1p4s8pgekg2di55_1528828742000-mysql-bin.000177.tar","identity0":"rm-bp1p4s8pgekg2di55","identity1":"1528828742000-mysql-bin.000177.tar","instanceId":"basisdataecommerce","jdbcUrl":"basisdataecommerce2.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1p4s8pgekg2di55/4500933/1528828742000-mysql-bin.000177.tar"}
2018-06-13 15:26:18 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1dq0cr4kk7j85ff_1528852880000-mysql-bin.000263.tar","identity0":"rm-bp1dq0cr4kk7j85ff","identity1":"1528852880000-mysql-bin.000263.tar","instanceId":"costmanagement","jdbcUrl":"costmanagement.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1dq0cr4kk7j85ff/4355593/1528852880000-mysql-bin.000263.tar"}
2018-06-13 15:26:18 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1dq0cr4kk7j85ff_1528831279000-mysql-bin.000262.tar","identity0":"rm-bp1dq0cr4kk7j85ff","identity1":"1528831279000-mysql-bin.000262.tar","instanceId":"costmanagement","jdbcUrl":"costmanagement.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1dq0cr4kk7j85ff/4355593/1528831279000-mysql-bin.000262.tar"}
2018-06-13 15:26:18 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp12z0brmm2d799lm_1528860734000-mysql-bin.000626.tar","identity0":"rm-bp12z0brmm2d799lm","identity1":"1528860734000-mysql-bin.000626.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator9.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp12z0brmm2d799lm/3882513/1528860734000-mysql-bin.000626.tar"}
2018-06-13 15:26:18 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp12z0brmm2d799lm_1528839132000-mysql-bin.000625.tar","identity0":"rm-bp12z0brmm2d799lm","identity1":"1528839132000-mysql-bin.000625.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator9.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp12z0brmm2d799lm/3882513/1528839132000-mysql-bin.000625.tar"}
2018-06-13 15:26:26 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(62) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-06-13 15:26:28 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -File does not exist: /pc/rm-bp1dq0cr4kk7j85ff/4355593/1528852880000-mysql-bin.000263.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

java.io.FileNotFoundException: File does not exist: /pc/rm-bp1dq0cr4kk7j85ff/4355593/1528852880000-mysql-bin.000263.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1211)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /pc/rm-bp1dq0cr4kk7j85ff/4355593/1528852880000-mysql-bin.000263.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at org.apache.hadoop.ipc.Client.call(Client.java:1470)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	... 19 more
2018-06-13 15:26:28 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -File does not exist: /pc/rm-bp1dq0cr4kk7j85ff/4355593/1528831279000-mysql-bin.000262.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

java.io.FileNotFoundException: File does not exist: /pc/rm-bp1dq0cr4kk7j85ff/4355593/1528831279000-mysql-bin.000262.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1211)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /pc/rm-bp1dq0cr4kk7j85ff/4355593/1528831279000-mysql-bin.000262.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at org.apache.hadoop.ipc.Client.call(Client.java:1470)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	... 19 more
2018-06-13 15:26:28 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp1dq0cr4kk7j85ff/4355593/1528831279000-mysql-bin.000262.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp1dq0cr4kk7j85ff/4355593/1528831279000-mysql-bin.000262.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:28 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -File does not exist: /pc/rm-bp12z0brmm2d799lm/3882513/1528839132000-mysql-bin.000625.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

java.io.FileNotFoundException: File does not exist: /pc/rm-bp12z0brmm2d799lm/3882513/1528839132000-mysql-bin.000625.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1211)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /pc/rm-bp12z0brmm2d799lm/3882513/1528839132000-mysql-bin.000625.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at org.apache.hadoop.ipc.Client.call(Client.java:1470)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	... 19 more
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp12z0brmm2d799lm/3882513/1528839132000-mysql-bin.000625.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp12z0brmm2d799lm/3882513/1528839132000-mysql-bin.000625.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:28 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -File does not exist: /pc/rm-bp1cowwkt73ni6271/4615201/1528835357000-mysql-bin.000102.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

java.io.FileNotFoundException: File does not exist: /pc/rm-bp1cowwkt73ni6271/4615201/1528835357000-mysql-bin.000102.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1211)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /pc/rm-bp1cowwkt73ni6271/4615201/1528835357000-mysql-bin.000102.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at org.apache.hadoop.ipc.Client.call(Client.java:1470)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	... 19 more
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp1cowwkt73ni6271/4615201/1528835357000-mysql-bin.000102.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp1cowwkt73ni6271/4615201/1528835357000-mysql-bin.000102.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1hzldabba9nhm68_1528839114000-mysql-bin.000626.tar","identity0":"rm-bp1hzldabba9nhm68","identity1":"1528839114000-mysql-bin.000626.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator10.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1hzldabba9nhm68/3882509/1528839114000-mysql-bin.000626.tar"}
2018-06-13 15:26:28 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -File does not exist: /pc/rm-bp1cowwkt73ni6271/4615201/1528813755000-mysql-bin.000101.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

java.io.FileNotFoundException: File does not exist: /pc/rm-bp1cowwkt73ni6271/4615201/1528813755000-mysql-bin.000101.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1211)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /pc/rm-bp1cowwkt73ni6271/4615201/1528813755000-mysql-bin.000101.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at org.apache.hadoop.ipc.Client.call(Client.java:1470)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	... 19 more
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp1cowwkt73ni6271/4615201/1528813755000-mysql-bin.000101.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp1cowwkt73ni6271/4615201/1528813755000-mysql-bin.000101.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1hzldabba9nhm68_1528817511000-mysql-bin.000625.tar","identity0":"rm-bp1hzldabba9nhm68","identity1":"1528817511000-mysql-bin.000625.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator10.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1hzldabba9nhm68/3882509/1528817511000-mysql-bin.000625.tar"}
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1hzldabba9nhm68_1528860716000-mysql-bin.000627.tar","identity0":"rm-bp1hzldabba9nhm68","identity1":"1528860716000-mysql-bin.000627.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator10.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1hzldabba9nhm68/3882509/1528860716000-mysql-bin.000627.tar"}
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp12z0brmm2d799lm_1528817530000-mysql-bin.000624.tar","identity0":"rm-bp12z0brmm2d799lm","identity1":"1528817530000-mysql-bin.000624.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator9.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp12z0brmm2d799lm/3882513/1528817530000-mysql-bin.000624.tar"}
2018-06-13 15:26:28 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -File does not exist: /pc/rm-bp1p4s8pgekg2di55/4500933/1528871946000-mysql-bin.000179.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

java.io.FileNotFoundException: File does not exist: /pc/rm-bp1p4s8pgekg2di55/4500933/1528871946000-mysql-bin.000179.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1211)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /pc/rm-bp1p4s8pgekg2di55/4500933/1528871946000-mysql-bin.000179.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at org.apache.hadoop.ipc.Client.call(Client.java:1470)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	... 19 more
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp1p4s8pgekg2di55/4500933/1528871946000-mysql-bin.000179.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp1p4s8pgekg2di55/4500933/1528871946000-mysql-bin.000179.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp19wpb29u91pbf6p_1528860008000-mysql-bin.000627.tar","identity0":"rm-bp19wpb29u91pbf6p","identity1":"1528860008000-mysql-bin.000627.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator11.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp19wpb29u91pbf6p/3882503/1528860008000-mysql-bin.000627.tar"}
2018-06-13 15:26:28 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -File does not exist: /pc/rm-bp12z0brmm2d799lm/3882513/1528860734000-mysql-bin.000626.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

java.io.FileNotFoundException: File does not exist: /pc/rm-bp12z0brmm2d799lm/3882513/1528860734000-mysql-bin.000626.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1211)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /pc/rm-bp12z0brmm2d799lm/3882513/1528860734000-mysql-bin.000626.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at org.apache.hadoop.ipc.Client.call(Client.java:1470)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	... 19 more
2018-06-13 15:26:28 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -File does not exist: /pc/rm-bp1p4s8pgekg2di55/4500933/1528850344000-mysql-bin.000178.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

java.io.FileNotFoundException: File does not exist: /pc/rm-bp1p4s8pgekg2di55/4500933/1528850344000-mysql-bin.000178.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1211)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /pc/rm-bp1p4s8pgekg2di55/4500933/1528850344000-mysql-bin.000178.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at org.apache.hadoop.ipc.Client.call(Client.java:1470)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	... 19 more
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp1p4s8pgekg2di55/4500933/1528850344000-mysql-bin.000178.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp1p4s8pgekg2di55/4500933/1528850344000-mysql-bin.000178.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp19wpb29u91pbf6p_1528838404000-mysql-bin.000626.tar","identity0":"rm-bp19wpb29u91pbf6p","identity1":"1528838404000-mysql-bin.000626.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator11.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp19wpb29u91pbf6p/3882503/1528838404000-mysql-bin.000626.tar"}
2018-06-13 15:26:28 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -File does not exist: /pc/rm-bp1p4s8pgekg2di55/4500933/1528828742000-mysql-bin.000177.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

java.io.FileNotFoundException: File does not exist: /pc/rm-bp1p4s8pgekg2di55/4500933/1528828742000-mysql-bin.000177.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1211)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /pc/rm-bp1p4s8pgekg2di55/4500933/1528828742000-mysql-bin.000177.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at org.apache.hadoop.ipc.Client.call(Client.java:1470)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	... 19 more
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp1p4s8pgekg2di55/4500933/1528828742000-mysql-bin.000177.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp1p4s8pgekg2di55/4500933/1528828742000-mysql-bin.000177.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp19wpb29u91pbf6p_1528816801000-mysql-bin.000625.tar","identity0":"rm-bp19wpb29u91pbf6p","identity1":"1528816801000-mysql-bin.000625.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator11.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp19wpb29u91pbf6p/3882503/1528816801000-mysql-bin.000625.tar"}
2018-06-13 15:26:28 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -File does not exist: /pc/rm-bp1cowwkt73ni6271/4615201/1528856961000-mysql-bin.000103.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

java.io.FileNotFoundException: File does not exist: /pc/rm-bp1cowwkt73ni6271/4615201/1528856961000-mysql-bin.000103.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1211)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /pc/rm-bp1cowwkt73ni6271/4615201/1528856961000-mysql-bin.000103.tar
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1999)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1970)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1883)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:700)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

	at org.apache.hadoop.ipc.Client.call(Client.java:1470)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	... 19 more
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp1cowwkt73ni6271/4615201/1528856961000-mysql-bin.000103.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp1cowwkt73ni6271/4615201/1528856961000-mysql-bin.000103.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:28 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp1dq0cr4kk7j85ff/4355593/1528852880000-mysql-bin.000263.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp1dq0cr4kk7j85ff/4355593/1528852880000-mysql-bin.000263.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp159o69998x3xe34_1528860950000-mysql-bin.000627.tar","identity0":"rm-bp159o69998x3xe34","identity1":"1528860950000-mysql-bin.000627.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator12.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp159o69998x3xe34/3882497/1528860950000-mysql-bin.000627.tar"}
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp12z0brmm2d799lm/3882513/1528860734000-mysql-bin.000626.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp12z0brmm2d799lm/3882513/1528860734000-mysql-bin.000626.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp159o69998x3xe34_1528817746000-mysql-bin.000625.tar","identity0":"rm-bp159o69998x3xe34","identity1":"1528817746000-mysql-bin.000625.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator12.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp159o69998x3xe34/3882497/1528817746000-mysql-bin.000625.tar"}
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp159o69998x3xe34_1528839349000-mysql-bin.000626.tar","identity0":"rm-bp159o69998x3xe34","identity1":"1528839349000-mysql-bin.000626.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator12.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp159o69998x3xe34/3882497/1528839349000-mysql-bin.000626.tar"}
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:352)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1073)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:968)
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp159o69998x3xe34/3882497/1528839349000-mysql-bin.000626.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp159o69998x3xe34/3882497/1528839349000-mysql-bin.000626.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp155hg16d7t501f6_1528871814000-mysql-bin.000175.tar","identity0":"rm-bp155hg16d7t501f6","identity1":"1528871814000-mysql-bin.000175.tar","instanceId":"debtcollection","jdbcUrl":"debtcollection.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp155hg16d7t501f6/4503501/1528871814000-mysql-bin.000175.tar"}
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:352)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1073)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:968)
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp1hzldabba9nhm68/3882509/1528860716000-mysql-bin.000627.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp1hzldabba9nhm68/3882509/1528860716000-mysql-bin.000627.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:352)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1073)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:968)
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp159o69998x3xe34/3882497/1528860950000-mysql-bin.000627.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp159o69998x3xe34/3882497/1528860950000-mysql-bin.000627.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp155hg16d7t501f6_1528828608000-mysql-bin.000173.tar","identity0":"rm-bp155hg16d7t501f6","identity1":"1528828608000-mysql-bin.000173.tar","instanceId":"debtcollection","jdbcUrl":"debtcollection.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp155hg16d7t501f6/4503501/1528828608000-mysql-bin.000173.tar"}
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:352)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1073)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:968)
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp1hzldabba9nhm68/3882509/1528817511000-mysql-bin.000625.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp1hzldabba9nhm68/3882509/1528817511000-mysql-bin.000625.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1382ojqe4u01d1t_1528853158000-mysql-bin.000105.tar","identity0":"rm-bp1382ojqe4u01d1t","identity1":"1528853158000-mysql-bin.000105.tar","instanceId":"paymentservice","jdbcUrl":"paymentservice.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1382ojqe4u01d1t/4613025/1528853158000-mysql-bin.000105.tar"}
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:352)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1073)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:968)
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp1hzldabba9nhm68/3882509/1528839114000-mysql-bin.000626.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp1hzldabba9nhm68/3882509/1528839114000-mysql-bin.000626.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1382ojqe4u01d1t_1528831556000-mysql-bin.000104.tar","identity0":"rm-bp1382ojqe4u01d1t","identity1":"1528831556000-mysql-bin.000104.tar","instanceId":"paymentservice","jdbcUrl":"paymentservice.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1382ojqe4u01d1t/4613025/1528831556000-mysql-bin.000104.tar"}
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp155hg16d7t501f6_1528850211000-mysql-bin.000174.tar","identity0":"rm-bp155hg16d7t501f6","identity1":"1528850211000-mysql-bin.000174.tar","instanceId":"debtcollection","jdbcUrl":"debtcollection.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp155hg16d7t501f6/4503501/1528850211000-mysql-bin.000174.tar"}
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:352)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1073)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:968)
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp159o69998x3xe34/3882497/1528817746000-mysql-bin.000625.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp159o69998x3xe34/3882497/1528817746000-mysql-bin.000625.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1d1ac1fa41jzf28_1528852237000-mysql-bin.000105.tar","identity0":"rm-bp1d1ac1fa41jzf28","identity1":"1528852237000-mysql-bin.000105.tar","instanceId":"customerservice","jdbcUrl":"customerservice.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1d1ac1fa41jzf28/4613047/1528852237000-mysql-bin.000105.tar"}
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:352)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1073)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:968)
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp19wpb29u91pbf6p/3882503/1528816801000-mysql-bin.000625.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp19wpb29u91pbf6p/3882503/1528816801000-mysql-bin.000625.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1d1ac1fa41jzf28_1528830635000-mysql-bin.000104.tar","identity0":"rm-bp1d1ac1fa41jzf28","identity1":"1528830635000-mysql-bin.000104.tar","instanceId":"customerservice","jdbcUrl":"customerservice.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1d1ac1fa41jzf28/4613047/1528830635000-mysql-bin.000104.tar"}
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:352)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1073)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:968)
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp19wpb29u91pbf6p/3882503/1528838404000-mysql-bin.000626.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp19wpb29u91pbf6p/3882503/1528838404000-mysql-bin.000626.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp11gox03jgt2ullb_1528844469000-mysql-bin.000114.tar","identity0":"rm-bp11gox03jgt2ullb","identity1":"1528844469000-mysql-bin.000114.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator8.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp11gox03jgt2ullb/4594755/1528844469000-mysql-bin.000114.tar"}
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:352)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1073)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:968)
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp19wpb29u91pbf6p/3882503/1528860008000-mysql-bin.000627.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp19wpb29u91pbf6p/3882503/1528860008000-mysql-bin.000627.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1h5j9w2o9335zsn_1528833730000-mysql-bin.000228.tar","identity0":"rm-bp1h5j9w2o9335zsn","identity1":"1528833730000-mysql-bin.000228.tar","instanceId":"rulesplatform-three","jdbcUrl":"rulesplatform-three.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1h5j9w2o9335zsn/4604515/1528833730000-mysql-bin.000228.tar"}
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.storage.HdfsStorage -HdfsStorage.java(63) -Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.; Host Details : local host is: "zxding1986deMacBook-Pro.local/192.168.201.55"; destination host is: "dn0":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1209)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1199)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1189)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:275)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:242)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:235)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1487)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:59)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.255.6:56248 remote=dn0/172.20.24.4:8020]. 59878 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:352)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1073)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:968)
2018-06-13 15:26:31 [ERROR] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(40) -error to consume message from rabbitmq because of open reader of file hdfs://dn0:8020/pc/rm-bp12z0brmm2d799lm/3882513/1528817530000-mysql-bin.000624.tar failed.
com.datatrees.datacenter.core.exception.BinlogException: open reader of file hdfs://dn0:8020/pc/rm-bp12z0brmm2d799lm/3882513/1528817530000-mysql-bin.000624.tar failed.
	at com.datatrees.datacenter.resolver.storage.HdfsStorage.openReader(HdfsStorage.java:64)
	at com.datatrees.datacenter.resolver.TaskProcessor.startRead(TaskProcessor.java:104)
	at com.datatrees.datacenter.resolver.RabbitMqProcessor$1.lambda$handleDelivery$2(RabbitMqProcessor.java:38)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-06-13 15:26:31 [ INFO] - com.datatrees.datacenter.resolver.TaskProcessor -RabbitMqProcessor.java(37) -start to read task desc {"identity":"rm-bp1xvc22l77p850ja_1528862553000-mysql-bin.000526.tar","identity0":"rm-bp1xvc22l77p850ja","identity1":"1528862553000-mysql-bin.000526.tar","instanceId":"basisdataoperator","jdbcUrl":"basisdataoperator7.mysql.rds.aliyuncs.com","path":"hdfs://dn0:8020/pc/rm-bp1xvc22l77p850ja/4038185/1528862553000-mysql-bin.000526.tar"}
